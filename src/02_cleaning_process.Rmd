---
title: "Cleaning"
author: "Kaushik Mohan"
date: "11/14/2018"
output:
  word_document: default
  html_document:
    df_print: paged
---


```{r setup, include=FALSE, echo=FALSE}
## Data Munging packages
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(tidyverse)
library(dplyr)
library(lubridate)
library(readxl)
library(stringr)
library(utils)
library(Hmisc)
```

```{r}
load(file="../data/pre_cleaning_sales_data.RData")
```

```{r}
commercial_condos <- c("RA","RB","RG","RH","RK","RP","RS","RP","RW","R5")
sales_data <- sales_data[!(sales_data$building_class_at_time_of_sale %in% commercial_condos),]
N <- dim(sales_data)[1]
```

```{r}
sales_data$BldgArea <- as.numeric(sales_data$BldgArea)
sales_data$ResArea <- as.numeric(sales_data$ResArea)
```


## Datasets

1. NYC Annualized Property Sales Data (2012-2017)
2. MapPLUTO (18v1)
3. Geoclient API v1.1

## Merging Process

1. Subset building classes A,B,C,D,R,S as these are the ones coming under the residential tax class
2. Merge with MapPLUTO data on `Borough`,`Block` and `Lot`
3. Condo listings don't merge as there is a mismatch in BBL with MapPLUTO data. Therefore, we use Geoclient API to get the `condominiumBillingBbl` for the condos and then merge with MapPLUTO data on the `BBL`.

## Cleaning Data

### 1. Sale Price

First, we analyse the distribution of the sale prices. We note a sharp peak at 1, which is a price of $\$10$. Also, from the overall distribution, we observe a lot of spikes below $\$10,000$ (red line). Hence, we choose to remove all the cases where the Price is less than $\$10,000$. 

```{r}
plot(density(log10(sales_data$sale_price)),main="Log(base 10) Sales Price")
abline(v=log10(10000),col=2)
```

```{r}
s2 <- sales_data %>% filter(sale_price == 0)
s3 <- sales_data %>% filter(sale_price <= 10000)
table(sales_data$building_class)
table(s2$building_class)
table(s3$building_class)
```

```{r}
sum(table(s2$building_class))/sum(table(sales_data$building_class))
sum(table(s3$building_class))/sum(table(sales_data$building_class))
```


```{r}
sales_data <- sales_data %>% filter(sale_price > 10000)
N_prev <- (1-(dim(sales_data)[1]/N))*100
paste0(round((1-(dim(sales_data)[1]/N))*100,2),"% rows removed")
```

### 2. Area

We need the area of the building because we would calculate the price per sq. ft which is a better measure than the sale price itself.

We use the GR.SQFT from the Property Assessment Roll.

We have `Gross Sq. Ft` in the Property Sales Data and Building Floor Area (`BldgArea`) Residential Floor Area (`ResArea`) in the MapPLUTO Data. We note that `Gross Sq. Ft` strongly associated and predicted by with both these with a slope of  nearly 1, except for the cases when the `Gross Sq. Ft` is 0, of course. Given `Bldg Area` has way fewer missing values, we choose to predict the missing values in `Gross Sq. Ft` with the using the `Bldg Area` from MapPLUTO data based on the simple linear model we fit on the non-missing ones. 

```{r}
round(table(sales_data$building_class[sales_data$GR.SQFT == 0])*100/table(sales_data$building_class),2)

sum(table(sales_data$building_class[sales_data$GR.SQFT == 0]))/dim(sales_data)[1]
```


### 3. Filtering by area

We see a few cases with area less than 100 sq.ft (red line). We remove these. 

```{r}
plot(density(log10(sales_data$GR.SQFT)),"Log(base 10) Area")
abline(v=log10(100),col=2)
```


```{r}
sales_data <- sales_data %>% filter(GR.SQFT > 100)
paste0(round((1-(dim(sales_data)[1]/N))*100 - N_prev,3),"% rows removed")
N_prev <- (1-(dim(sales_data)[1]/N))*100
```

### 4. Price per sq. ft

We compute Price per square feet from the sale price and above computed area. Apartments and Coops don't have area for each unit and therefore we approximate those to be total area of the building divided by the total units in the building. Any recod with price per sq. ft < 100 is multiplied by total number of units. 

Looking at the distribution, we see a two modes around $\$10$ per sq. feet and $\$1000$ per sq.ft with a dip around $\$50$ (red line). 

```{r}
sales_data$price_per_sqft <- sales_data$sale_price/sales_data$GR.SQFT
sales_data$price_per_sqft[sales_data$price_per_sqft < 100] <- sales_data$price_per_sqft[sales_data$price_per_sqft < 100]*sales_data$TOT.UNIT[sales_data$price_per_sqft < 100]
```

```{r}
plot(density(log10(sales_data$price_per_sqft)),main="Log(base 10) Price per sq. ft")
abline(v=log10(50),col=2)
```

```{r}
s2 <- sales_data$building_class[sales_data$price_per_sqft <= 50]
table(sales_data$building_class)
table(s2)
```


```{r}
sales_data <- sales_data %>% filter(price_per_sqft > 50)
paste0(round((1-(dim(sales_data)[1]/N))*100 - N_prev,2),"% rows removed")
N_prev <- (1-(dim(sales_data)[1]/N))*100

```


#### 4.1 Checking Price Distributions

Below are the marginals by Borough and Building class and distributions of price per square feet by building class. 

```{r}

sales_data %>% group_by(borough) %>% 
  summarise(median_price_per_sqft = median(price_per_sqft))

sales_data %>% group_by(building_class) %>% 
  summarise(median_price_per_sqft = median(price_per_sqft))

sales_data %>% group_by(borough,building_class) %>% 
  summarise(median_price_per_sqft = median(price_per_sqft))

```



```{r}
## Fixing years
sales_data$year[is.na(sales_data$year)] <- year(as.Date(sales_data$sale_date[is.na(sales_data$year)],origin="1900-01-01")) 

## adding tract as per census
sales_data$Tract2010 <- str_pad(sales_data$Tract2010,6,side="right",pad="0")
sales_data$boro_ct201 <- paste0(sales_data$borough,sales_data$Tract2010)

```


```{r}
save(sales_data,file="../data/cleaned_sales_data.RData")
```

